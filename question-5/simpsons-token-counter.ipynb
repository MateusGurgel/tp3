{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalando dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.2-cp310-cp310-win_amd64.whl (7.8 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "     ---------------------------------------- 0.0/218.6 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 41.0/218.6 kB 960.0 kB/s eta 0:00:01\n",
      "     ---------------------------- --------- 163.8/218.6 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 218.6/218.6 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.3/2.2 MB 5.9 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 0.8/2.2 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.4/2.2 MB 9.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.2 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.2/2.2 MB 10.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install joblib\n",
    "%pip install tiktoken\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando a base de dados dos simpsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_script = pd.read_csv('./data/thesimpsons/simpsons_script_lines.csv', low_memory=False)\n",
    "df_episodes = pd.read_csv('./data/thesimpsons/simpsons_episodes.csv', low_memory=False)\n",
    "df_characters = pd.read_csv('./data/thesimpsons/simpsons_characters.csv', low_memory=False)\n",
    "df_locations = pd.read_csv('./data/thesimpsons/simpsons_locations.csv', low_memory=False)\n",
    "\n",
    "df_script.set_index('id', inplace=True)\n",
    "df_characters['id'] = df_characters['id'].astype(str)\n",
    "\n",
    "df_characters = df_characters.add_prefix('character_')\n",
    "df_locations = df_locations.add_prefix('location_')\n",
    "df_episodes = df_episodes.add_prefix('episode_')\n",
    "\n",
    "data = (\n",
    "    df_script.merge(df_episodes, left_on='episode_id', right_on='episode_id')\n",
    "             .merge(df_characters, left_on='character_id', right_on='character_id', how='left')\n",
    "             .merge(df_locations, left_on='location_id', right_on='location_id', how='left')\n",
    ")\n",
    "\n",
    "\n",
    "assert data.shape[0] == df_script.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "\n",
    "# Carga dos resumos\n",
    "summaries = joblib.load('../data/results/simpsons_episode_summary.joblib')\n",
    "print(summaries.keys())\n",
    "\n",
    "data = pd.read_parquet('../data/results/database_thesimpsons.parquet')\n",
    "\n",
    "\n",
    "data['line'] = (\"Espisode \" + data['episode_id'].astype(str) + ' | ' + \n",
    "                data['location_normalized_name'].fillna('') + ', ' + \n",
    "                data['character_normalized_name'].fillna('') + ' said: ' + \n",
    "                data['normalized_text'].fillna('')\n",
    ")\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimativa de Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def get_tokens(text: str):\n",
    "    encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoder.encode(text)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132087, 31)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.dropna(subset='normalized_text').copy()\n",
    "X['n_tokens'] = X.normalized_text.fillna('').apply(lambda x: len(get_tokens(x)))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a média de tokens por episódio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O episódio com mais tokens é o 49 com 3454 tokens.\n",
      "A média de tokens por episódio é de 2606.98\n"
     ]
    }
   ],
   "source": [
    "token_per_episode = X.groupby('episode_id').n_tokens.sum()\n",
    "general_token_mean = token_per_episode.mean()\n",
    "most_tokens_episode = token_per_episode.idxmax()\n",
    "\n",
    "print(\"O episódio com mais tokens é o\", most_tokens_episode, \"com\", token_per_episode[most_tokens_episode], \"tokens.\")\n",
    "print(\"A média de tokens por episódio é de {:.2f}\".format(general_token_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a média de tokens por temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O episódio com mais tokens é o 49 com 3454 tokens.\n",
      "A média de tokens por episódio é de 2606.98\n"
     ]
    }
   ],
   "source": [
    "token_per_episode = X.groupby('episode_id').n_tokens.sum()\n",
    "general_token_mean = token_per_episode.mean()\n",
    "most_tokens_episode = token_per_episode.idxmax()\n",
    "\n",
    "print(\"O episódio com mais tokens é o\", most_tokens_episode, \"com\", token_per_episode[most_tokens_episode], \"tokens.\")\n",
    "print(\"A média de tokens por episódio é de {:.2f}\".format(general_token_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
