{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalando dependÃªncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: google-generativeai in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.10.1)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (5.28.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.154.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-decouple in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (3.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install joblib\n",
    "%pip install tiktoken\n",
    "%pip install matplotlib\n",
    "%pip install -U google-generativeai\n",
    "%pip install python-decouple\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando a base de dados dos simpsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_script = pd.read_csv('./data/thesimpsons/simpsons_script_lines.csv', low_memory=False)\n",
    "df_episodes = pd.read_csv('./data/thesimpsons/simpsons_episodes.csv', low_memory=False)\n",
    "df_characters = pd.read_csv('./data/thesimpsons/simpsons_characters.csv', low_memory=False)\n",
    "df_locations = pd.read_csv('./data/thesimpsons/simpsons_locations.csv', low_memory=False)\n",
    "\n",
    "df_script.set_index('id', inplace=True)\n",
    "df_characters['id'] = df_characters['id'].astype(str)\n",
    "\n",
    "df_characters = df_characters.add_prefix('character_')\n",
    "df_locations = df_locations.add_prefix('location_')\n",
    "df_episodes = df_episodes.add_prefix('episode_')\n",
    "\n",
    "data = (\n",
    "    df_script.merge(df_episodes, left_on='episode_id', right_on='episode_id')\n",
    "             .merge(df_characters, left_on='character_id', right_on='character_id', how='left')\n",
    "             .merge(df_locations, left_on='location_id', right_on='location_id', how='left')\n",
    ")\n",
    "\n",
    "\n",
    "assert data.shape[0] == df_script.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "\n",
    "# Carga dos resumos\n",
    "summaries = joblib.load('../data/results/simpsons_episode_summary.joblib')\n",
    "print(summaries.keys())\n",
    "\n",
    "data = pd.read_parquet('../data/results/database_thesimpsons.parquet')\n",
    "\n",
    "\n",
    "data['line'] = (\"Espisode \" + data['episode_id'].astype(str) + ' | ' + \n",
    "                data['location_normalized_name'].fillna('') + ', ' + \n",
    "                data['character_normalized_name'].fillna('') + ' said: ' + \n",
    "                data['normalized_text'].fillna('')\n",
    ")\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimativa de Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def get_tokens(text: str):\n",
    "    encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoder.encode(text)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132087, 31)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.dropna(subset='normalized_text').copy()\n",
    "X['n_tokens'] = X.normalized_text.fillna('').apply(lambda x: len(get_tokens(x)))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a mÃ©dia de tokens por episÃ³dio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O episÃ³dio com mais tokens Ã© o 49 com 3454 tokens.\n",
      "A mÃ©dia de tokens por episÃ³dio Ã© de 2606.98\n"
     ]
    }
   ],
   "source": [
    "token_per_episode = X.groupby('episode_id').n_tokens.sum()\n",
    "general_token_mean = token_per_episode.mean()\n",
    "most_tokens_episode = token_per_episode.idxmax()\n",
    "\n",
    "print(\"O episÃ³dio com mais tokens Ã© o\", most_tokens_episode, \"com\", token_per_episode[most_tokens_episode], \"tokens.\")\n",
    "print(\"A mÃ©dia de tokens por episÃ³dio Ã© de {:.2f}\".format(general_token_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a mÃ©dia de tokens por temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A season com mais tokens Ã© a 7 com 70418 tokens.\n",
      "A mÃ©dia de tokens por temporada Ã© de 56551.46153846154\n"
     ]
    }
   ],
   "source": [
    "token_per_season = X.groupby('episode_season').n_tokens.sum()\n",
    "general_token_mean = token_per_season.mean()\n",
    "most_tokens_season = token_per_season.idxmax()\n",
    "\n",
    "print(\"A season com mais tokens Ã© a\", most_tokens_season, \"com\", token_per_season[most_tokens_season], \"tokens.\")\n",
    "print(\"A mÃ©dia de tokens por temporada Ã© de\", general_token_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining para fazer uma anÃ¡lise descritiva das avaliaÃ§Ãµes do IMDB e da audiÃªncia dos episÃ³dios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['episode_id', 'episode_season', 'episode_imdb_rating', 'episode_views']\n",
    "episode_stats = data[cols].drop_duplicates()\n",
    "episode_stats.to_csv('episode_stats.csv', sep=';', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levantando dados importantes sobre o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from decouple import config\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=config(\"GEMINI_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "csv_input = pd.read_csv('episode_stats.csv', nrows=100)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a data scientist specialized in creating descriptive analisys. \n",
    "['episode_id', 'episode_season', 'episode_imdb_rating', 'episode_views'] in series_data.csv.\n",
    "\n",
    "- series_data.csv: is a CSV file splitted by ';' and with the following columns:\n",
    "\n",
    "- episode_id: unique episode index\n",
    "- episode_season: episode season number\n",
    "- episode_imdb_rating: IMDB rating of the episode \n",
    "- episode_views: total views of the episode in milions.\n",
    "\n",
    "- All the data is from THE SIMPSONS series.\n",
    "\n",
    "1. The goal is to try to data, trends and a meaningful numbers of the data. \n",
    "3. make a mean of views and rating per season.\n",
    "4. Bring relevant data.\n",
    "5. do not add any thoughts or opinions.\n",
    "6. Talk only about data\n",
    "7. Do not Talk abou code or programming. Just data.\n",
    "8. Give the max quanity of data possible.\n",
    "\n",
    "\n",
    "<series_data.csv>\n",
    "    {csv_input}\n",
    "</series_data.csv>\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "important_data = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divagando sobre os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a data scientist specialized in creating insights about data\n",
    "\n",
    "You will recive a bunch of numbers, insights and trends about a dataset.\n",
    "\n",
    "1. The goal is to try to capture insights, trends and a meaningful analysis of the data. \n",
    "2. Just talk about the data, don't worry about the code.\n",
    "3. Talk A Lot of the data\n",
    "4. Make all the analysis you can.\n",
    "5. add thoughts and opinions.\n",
    "6. Allways be very detailed and specific.\n",
    "\n",
    "\n",
    "<data>\n",
    "    {important_data}\n",
    "</data>\n",
    "\"\"\"\n",
    "\n",
    "important_insights = model.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilando em uma resposta final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a data scientist specialized in Teaching and resuming important Data\n",
    "\n",
    "You will recive a bunch of insights and information about a dataset.\n",
    "\n",
    "1. The goal is resume the data in a very detailed way.\n",
    "2. Just talk about the data, don't worry about the code.\n",
    "3. Resume the data in a very detailed way.\n",
    "4. Make everything very clear.\n",
    "5. add thoughts and opinions.\n",
    "6. Make a very detailed, but small resume of the data\n",
    "\n",
    "<data>\n",
    "    {important_data}\n",
    "</data>\n",
    "\"\"\"\n",
    "\n",
    "important_insights = model.generate_content(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Detailed Data Resume: The Simpsons Series Data Analysis\\n\\nThis analysis presents a limited overview of The Simpsons TV show, based on a sample of 100 episodes drawn from seasons 2, 6, and 12.  The dataset's incompleteness is a significant limitation, preventing a complete picture of the show's performance across its entire run.  We can, however, draw some preliminary conclusions from the available data.\\n\\n**Data Scope and Limitations:**\\n\\nThe most striking aspect of this dataset is its incompleteness.  Only three seasons are represented (2, 6, and 12), and the exact number of episodes per season within the sample is not specified. This immediately raises concerns about the generalizability of any findings.  The sample might not be representative of the entire series, potentially leading to biased conclusions.  For instance, seasons 2 and 6 show higher average IMDB ratings and views than season 12.  This could reflect genuine differences in quality or popularity across these seasons, but it could also simply reflect a non-random sampling bias.  A more robust analysis would require data from all 34 seasons, ideally with a clear sampling methodology to ensure representativeness.\\n\\n**Key Findings:**\\n\\nThe analysis focuses on two key metrics: IMDB rating (a measure of critical and audience reception) and views (in millions, a measure of popularity).  The descriptive statistics provided offer a glimpse into the performance of the show across the sampled seasons:\\n\\n\\n* **Season 2:**  This season boasts a mean IMDB rating of 8.267 and a mean viewership of 51,723,333.  These figures suggest a relatively high level of both critical acclaim and audience engagement.\\n\\n* **Season 6:**  Season 6 shows even higher average ratings (8.4) and views (69,964,800), suggesting a peak in the show's popularity during this period.  It is, however, important to consider the limitations of this data. The higher views could result from increased viewership overall.  Correlation, but not causality, can be demonstrated.\\n\\n* **Season 12:**  In contrast to seasons 2 and 6, season 12 displays a lower mean IMDB rating (7.15) and fewer average views (49,438,000).  This could indicate a decline in the show's popularity and critical reception, or simply reflect the fact that this sample of episodes may have performed less well than those chosen from the earlier seasons.\\n\\n\\n**Data Variability and Missing Information:**\\n\\nThe data description highlights significant variability in both IMDB ratings and episode views. This underscores the need for further exploration. A full analysis would need to consider the distribution of ratings and views, look for outliers, and investigate the reasons behind this variability.  Simply knowing the average viewership and rating does not capture the whole picture. A deeper analysis could explore correlations between specific episodes, ratings, specific plotlines, and other variables, including the year of release, to understand more deeply the relationship between critical reception and viewership.  The absence of episode-level data prevents us from delving deeper into this kind of analysis.\\n\\n**Recommendations for Future Analysis:**\\n\\nTo improve the understanding of The Simpsons' performance, the following are recommended:\\n\\n* **Expand the Dataset:** Include data from all 34 seasons to provide a complete and representative view of the show's history.\\n* **Detailed Episode-Level Data:**  Collect data at the episode level, including individual IMDB ratings and view counts, allowing for a more granular analysis of the factors influencing popularity and critical reception.  Additionally, this would allow the use of a wider variety of analytic methods beyond simple averages.\\n* **Multivariate Analysis:** Explore the relationships between IMDB ratings, viewership, and other relevant variables (e.g., air date, episode type, guest stars) to identify key drivers of the show's success and understand how they changed over time.\\n* **Time Series Analysis:** Analyze trends in viewership and ratings over time to understand patterns and changes in the show's performance.\\n\\n\\nIn conclusion, while this limited dataset offers a rudimentary understanding of The Simpsons' performance in selected seasons, a significantly more comprehensive dataset and a deeper analytical approach are necessary to draw robust and generalizable conclusions.  The current analysis serves primarily as a starting point, highlighting the need for more extensive research.\\n\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_insights.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
