{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalando dependÃªncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (5.28.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: pydantic in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.10.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-generativeai) (2.154.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-decouple in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (3.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\mateus\\projects\\infnet\\promteng\\tp3\\venv\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install -U google-generativeai\n",
    "%pip install python-decouple\n",
    "%pip install python-dotenv\n",
    "\n",
    "%pip install sacrebleu\n",
    "%pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um promt para resumo de chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from decouple import config\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=config(\"GEMINI_KEY\"))\n",
    "\n",
    "def generate_chunks_summary(chunks: List[str]) -> str:\n",
    "\n",
    "    formated_quotes = \"\\n\".join([f\"<quote>{quote}</quote>\" for quote in chunks])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    <summarizer>\n",
    "        You are a assistant created to emulate the best summarizer model in the world. Created to summarize quotes of a television show.\n",
    "    </summarizer>\n",
    "\n",
    "    1. Allways resume the important information.\n",
    "    3. Keep the summary detailed\n",
    "    4. Do not include your own opinion.\n",
    "    5. Do not include any new information.\n",
    "    6. Do not include any examples.\n",
    "    7. Do not include any quotes.\n",
    "    8. Never break the main idea of the text.\n",
    "    9. Those chunks are from the same episode of a television show.\n",
    "    \n",
    "    {formated_quotes}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um promt para resumo de falas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from decouple import config\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=config(\"GEMINI_KEY\"))\n",
    "\n",
    "def generate_quote_summary(quotes: List[str]) -> str:\n",
    "\n",
    "    formated_quotes = \"\\n\".join([f\"<quote>{quote}</quote>\" for quote in quotes])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    <summarizer>\n",
    "        You are a assistant created to emulate the best summarizer model in the world. Created to summarize quotes of a television show.\n",
    "    </summarizer>\n",
    "\n",
    "    1. Allways resume the important information.\n",
    "    2. Leave out unimportant details.\n",
    "    3. Keep the summary detailed\n",
    "    4. Do not include your own opinion.\n",
    "    5. Do not include any new information.\n",
    "    6. Do not include any examples.\n",
    "    7. Do not include any quotes.\n",
    "    8. Never break the main idea of the text.\n",
    "    \n",
    "    {formated_quotes}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_chunks(quote_list: List[str], chunk_size: int, intersection_size: int) -> List[List[str]]:\n",
    "    quotes_size = len(quote_list)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range(0, quotes_size, chunk_size):\n",
    "        start = i if i - intersection_size < 0 else i - intersection_size\n",
    "        end = start + chunk_size\n",
    "        selected_quotes = quote_list[start:end]\n",
    "        result.append(selected_quotes)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateus\\AppData\\Local\\Temp\\ipykernel_14616\\1308231324.py:3: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./data/thesimpsons/simpsons_script_lines.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/thesimpsons/simpsons_script_lines.csv\")\n",
    "df = df.dropna(subset=[\"normalized_text\"])\n",
    "chosen_quotes = df[df[\"episode_id\"] == 92]\n",
    "\n",
    "chunks = get_chunks(chosen_quotes[\"normalized_text\"].tolist(), 100, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_resume = [generate_quote_summary(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resume = generate_chunks_summary(chunks_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16329704759666938"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "bleu_scorer = BLEU()\n",
    "\n",
    "score = bleu_scorer.sentence_score(\n",
    "    hypothesis=final_resume,\n",
    "    references=chunks_resume,\n",
    ")\n",
    "\n",
    "score.score/100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L-F 0.321428566431406\n",
      "ROUGE-L-R 0.32926829268292684\n",
      "ROUGE-L-P 0.313953488372093\n",
      "ROUGE-L-F 0.24539876802137842\n",
      "ROUGE-L-R 0.2597402597402597\n",
      "ROUGE-L-P 0.23255813953488372\n",
      "ROUGE-L-F 0.24999999518904328\n",
      "ROUGE-L-R 0.3103448275862069\n",
      "ROUGE-L-P 0.20930232558139536\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "hypothesis = \"to make people trustworthy you need to trust them\"\n",
    "reference = \"the way to make people trustworthy is to trust them\"\n",
    "\n",
    "for chunk in chunks_resume:\n",
    "    score = rouge_scorer.get_scores(\n",
    "        hyps=final_resume,\n",
    "        refs=chunk,\n",
    "    )\n",
    "    print('ROUGE-L-F', score[0][\"rouge-l\"][\"f\"])\n",
    "    print('ROUGE-L-R', score[0][\"rouge-l\"]['r'])\n",
    "    print('ROUGE-L-P', score[0][\"rouge-l\"]['p'])\n",
    "    print(\"=====================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
